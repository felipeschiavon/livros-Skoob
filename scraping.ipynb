{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "import bs4 as bs4\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minerando dados Editoras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Url onde estão todas as editoras\n",
    "\n",
    "url_editoras = 'https://www.skoob.com.br/editoras/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo request do link e transformando em um objeto do bs4\n",
    "\n",
    "response = rq.get(url_editoras)\n",
    "pagina_html = bs4.BeautifulSoup(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procurando tags\n",
    "\n",
    "tags = pagina_html.findAll(id=\"resultadoBusca-\")\n",
    "editoras = tags[0].findAll('strong')\n",
    "\n",
    "lista_editoras = []\n",
    "lista_links = []\n",
    "\n",
    "for x in editoras:\n",
    "    if x.find('a') != None:\n",
    "        editora = x.get_text()\n",
    "        lista_editoras.append(editora)\n",
    "        \n",
    "        link = x.find('a').get('href')\n",
    "        lista_links.append(link)\n",
    "        \n",
    "livros_editora = []\n",
    "numero_livros = tags[0].findAll('span')\n",
    "\n",
    "for livros in range(1, len(numero_livros), 8):\n",
    "    n_livros = numero_livros[livros].get_text().split()[0]\n",
    "    n_livros = n_livros.replace('.', '')\n",
    "    livros_editora.append(n_livros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando dataframe que armazenará os dados\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['editora'] = lista_editoras\n",
    "df['link'] = lista_links\n",
    "df['qtde_livros'] = livros_editora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para ser aplicada em cada linha do dataframe na coluna código\n",
    "# Parâmetro x: string -> link da editora\n",
    "# Irá retornar o código da editora\n",
    "\n",
    "def codigo(x):\n",
    "    return x.split('/')[-1].split('-')[0]\n",
    "\n",
    "codigos = df['link'].apply(codigo)\n",
    "df['codigo'] = codigos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe com as editoras\n",
    "\n",
    "df.to_csv('./editoras_link.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minerando livros e link de cada editora\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os livros de cada editora estão no link : \"https://www.skoob.com.br/editora/livros/codigoDeCadaEditora\"  \n",
    "É necessário o código de cada editora para entrar na página dos livros. Os códigos foram salvos no editoras_link.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_livros = []\n",
    "lista_livros_link = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    print('--------------------------')\n",
    "    print(df['editora'][index])\n",
    "    \n",
    "    \n",
    "    url_base = 'https://www.skoob.com.br/editora/livros/{}/mpage:{}'\n",
    "    \n",
    "    # Número de páginas com livros\n",
    "    # Cada página do site mostra 40 livros\n",
    "    n_page = math.ceil(int(df['qtde_livros'][index])/40) + 1\n",
    "    \n",
    "    for x in range(1, n_page):\n",
    "        print(x)\n",
    "        url_livros = url_base.format(df['codigo'][index], x)\n",
    "        \n",
    "        response = rq.get(url_livros)\n",
    "        pagina_html = bs4.BeautifulSoup(response.text)\n",
    "        \n",
    "        lista_div = pagina_html.findAll(\"div\", {\"class\": \"box_livro\"})\n",
    "        \n",
    "        for x in lista_div:\n",
    "            titulo = x.find('h3').get_text()\n",
    "            link = x.find('a').get('href')\n",
    "            \n",
    "            lista_livros.append(titulo)\n",
    "            lista_livros_link.append(link)\n",
    "        \n",
    "        time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando dataframe\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['livros'] = lista_livros\n",
    "df['link'] = lista_livros_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe com as editoras\n",
    "\n",
    "df.to_csv('./livros_link.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Livros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./livros_link.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_livros = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    livro = {}\n",
    "    \n",
    "    # De 10 em 10 request espera 1 segundo\n",
    "    if index % 10 == 0:\n",
    "        time.sleep(1)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # Request para a paǵina do livro\n",
    "        url_base = 'https://www.skoob.com.br{}'.format(df['link'][index])        \n",
    "        response = rq.get(url_base)\n",
    "        pagina_html = bs4.BeautifulSoup(response.text)\n",
    "        \n",
    "        # Titulo\n",
    "        div_lateral = pagina_html.find(\"div\", {\"id\": \"pg-livro-menu-principal\"})\n",
    "        livro['titulo'] = div_lateral.find('strong').get_text()\n",
    "\n",
    "        #print(f'{index} - {titulo}')\n",
    "        #print(url_base)\n",
    "        \n",
    "        # Autor\n",
    "        livro['autor'] = div_lateral.findAll('a')[1].get_text()\n",
    "        \n",
    "        # ISBN \n",
    "        div_menor = div_lateral.find('div', {\"class\": \"sidebar-desc\"})\n",
    "        isbns = div_menor.findAll('span')\n",
    "        try:\n",
    "            livro['ISBN_13'] = str(isbns[0]).split('>')[1].split('<')[0]\n",
    "            livro['ISBN_10'] = str(isbns[1]).split('>')[1].split('<')[0]\n",
    "        except:\n",
    "            livro['ISBN_13'] = ''\n",
    "            livro['ISBN_10'] = ''\n",
    "            \n",
    "        \n",
    "        # Texto com dados\n",
    "        texto = div_menor.get_text()\n",
    "        \n",
    "        try:    \n",
    "            livro['ano'] = texto.split('Ano: ')[1].split(' ')[0]\n",
    "        except:\n",
    "            livro['ano'] = ''\n",
    "        \n",
    "        try:\n",
    "            livro['paginas'] = texto.split('Páginas: ')[1].split(' ')[0]\n",
    "        except:\n",
    "            livro['paginas'] = ''\n",
    "            \n",
    "        try:\n",
    "            livro['idioma'] = texto.split('Idioma: ')[1].split(' ')[0]\n",
    "        except:\n",
    "            livro['idioma'] = ''\n",
    "        \n",
    "        try:\n",
    "            livro['editora'] = texto.split('Editora: ')[1].split(' ')[0]\n",
    "        except:\n",
    "            livro['editora'] = ''\n",
    "            \n",
    "\n",
    "        div_superior = pagina_html.find('div', {'id': 'livro-perfil-status'})\n",
    "        \n",
    "        try:\n",
    "             livro['rating'] = div_superior.find('span', {'class': 'rating'}).get_text()\n",
    "        except:\n",
    "             livro['rating'] = ''\n",
    "        \n",
    "        try:\n",
    "            livro['avaliacao'] = div_superior.find('div', {'id': 'pg-livro-box-rating-avaliadores-numero'}).get_text().split(' ')[0]\n",
    "        except:\n",
    "            livro['avaliacao'] = ''\n",
    "\n",
    "\n",
    "        info = div_superior.findAll('a', {'class': 'text_blue'})\n",
    "        \n",
    "        try:\n",
    "            livro['resenha'] = info[0].get_text()\n",
    "        except:\n",
    "            livro['resenha'] = ''\n",
    "            \n",
    "        try:\n",
    "            livro['abandonos']  = info[1].get_text()\n",
    "        except:\n",
    "            livro['abandonos'] = ''\n",
    "        \n",
    "        try:\n",
    "            livro['relendo']  = info[2].get_text()\n",
    "        except:\n",
    "            livro['relendo'] = ''\n",
    "            \n",
    "        try:   \n",
    "            livro['querem_ler'] = info[3].get_text()\n",
    "        except:\n",
    "            livro['querem_ler'] = ''\n",
    "        \n",
    "        try:\n",
    "            livro['lendo'] = info[4].get_text()\n",
    "        except:\n",
    "            livro['lendo'] = ''\n",
    "            \n",
    "        try:\n",
    "            livro['leram'] = info[5].get_text()\n",
    "        except:\n",
    "            livro['leram'] = ''\n",
    "\n",
    "\n",
    "        info = pagina_html.find('p', {'itemprop': 'description'})\n",
    "        \n",
    "        try: \n",
    "            descricao = info.get_text().replace('\\n', '')\n",
    "            descricao = descricao.split('.')\n",
    "            genero = descricao[-1]\n",
    "            descricao = ''.join(descricao[:-1])\n",
    "            livro['descricao'] = descricao\n",
    "            livro['genero'] = genero\n",
    "        except:\n",
    "            livro['descricao'] = ''\n",
    "            livro['genero'] = ''\n",
    "            \n",
    "        \n",
    "        try: \n",
    "            info = pagina_html.find('span', {'class': 'pg-livro-icone-male-label'})\n",
    "            livro['male'] = int(info.get_text().replace('%', ''))\n",
    "\n",
    "            info = pagina_html.find('span', {'class': 'pg-livro-icone-female-label'})\n",
    "            livro['female'] = int(info.get_text().replace('%', ''))\n",
    "        \n",
    "        except: \n",
    "            livro['male'] = 0\n",
    "            livro['female'] = 0\n",
    "            \n",
    "        info_livros.append(livro)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algumas páginas possuem um formato diferente para mostrar o nome do autor\n",
    "# As instâncias que estão com erro possuem autor como : \\nR$ \\n\n",
    "\n",
    "for index, row in dd.iterrows():\n",
    "    \n",
    "    # Verificando se autor está errado\n",
    "    if dd['autor'][index] == '\\nR$ \\n':\n",
    "        \n",
    "        livro = dd['titulo'][index]\n",
    "        link = df[df['livros'] == livro].reset_index()\n",
    "        \n",
    "        try:\n",
    "            url_base = 'https://www.skoob.com.br{}'.format(link['link'][0])\n",
    "            response = rq.get(url_base)\n",
    "            pagina_html = bs4.BeautifulSoup(response.text)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            autor = pagina_html.find(\"i\", {\"class\": \"sidebar-subtitulo\"}).get_text()\n",
    "        except:\n",
    "            autor = ''\n",
    "            print(url_base)\n",
    "            \n",
    "        dd.at[index, 'autor'] = autor\n",
    "        print(autor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando dataset atualizado\n",
    "\n",
    "dd.to_csv('./dados.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alguns livros possuem outro formato no nome do autor\n",
    "# +/- 25 livros, vou apenas dropar esses registros\n",
    "\n",
    "linhas_drop = df[df['autor'] == '\\nR$ \\n'].index\n",
    "df.drop(index= linhas_drop, inplace=True)\n",
    "df.to_csv('dados_ok_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organizando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar linhas vazias em cada coluna\n",
    "\n",
    "for x in df.columns:\n",
    "\n",
    "    nan_rows = df[df[x].isnull()]\n",
    "    print(f\"Número de linhas vazias na coluna: {x} = {nan_rows.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando datasets\n",
    "\n",
    "livros_link = pd.read_csv('./livros_link.csv')\n",
    "df = pd.read_csv('dados.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correção dos dados faltantes da coluna de autores\n",
    "\n",
    "for index, row in df[df['autor'].isnull()].iterrows():\n",
    "    \n",
    "    livro = df['titulo'][index]\n",
    "    link = livros_link[livros_link['livros'] == livro].reset_index()\n",
    "    url_base = 'https://www.skoob.com.br{}'.format(link['link'][0])\n",
    "    \n",
    "    response = rq.get(url_base)\n",
    "    pagina_html = bs4.BeautifulSoup(response.text)\n",
    "    \n",
    "    try:\n",
    "        autor = pagina_html.find(\"h3\", {\"class\": \"secao-subtitulo\"}).get_text()\n",
    "    except:\n",
    "        autor = ''\n",
    "        \n",
    "    df.at[index, 'autor'] = autor\n",
    "    print(autor)\n",
    "\n",
    "# Salvando dataset com dados novos\n",
    "df.to_csv('./dados.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrigindo ISBN\n",
    "# Transformando dado em str\n",
    "\n",
    "df['ISBN_10'] = df['ISBN_10'].astype('str')\n",
    "df['ISBN_13'] = df['ISBN_13'].astype('str')\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    try:\n",
    "        # Removendo .\n",
    "        df.at[index, 'ISBN_13'] = df['ISBN_13'][index].split('.')[0]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformando ano em um inteiro\n",
    "\n",
    "def to_int(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except:\n",
    "        return(0)\n",
    "\n",
    "df['ano'] = df['ano'].apply(to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrigindo tipo das variáveis\n",
    "\n",
    "df['paginas'] = df['paginas'].apply(to_int)\n",
    "df['idioma'] = df['idioma'].astype('str')\n",
    "df['avaliacao'] = df['avaliacao'].astype('int')\n",
    "df['resenha'] = df['resenha'].astype('int')\n",
    "df['abandonos'] = df['abandonos'].astype('int')\n",
    "df['relendo'] = df['relendo'].astype('int')\n",
    "df['querem_ler'] = df['querem_ler'].astype('int')\n",
    "df['lendo'] = df['lendo'].astype('int')\n",
    "df['leram'] = df['leram'].astype('int')\n",
    "df['descricao'] = df['descricao'].astype('str')\n",
    "df['genero'] = df['genero'].astype('str')\n",
    "df['editora'] = df['editora'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando dataset final\n",
    "\n",
    "df.to_csv('./dados.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
